---
title: Designing a PostrgreSQL db for acoustic telemetry
author: Seb
date: '2021-01-13'
slug: designing-a-postrgresql-db-for-acoustic-telemetry
categories:
  - database
  - acoustic telemetry
tags:
  - postgresql
  - r
  - acoustic telemetry
draft: true
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>This is a series of posts that will aim to:<br />
1. outline a philosophy and structure for the ideal acoustic telemetry database<br />
1. justify this philosophy and structure within the context of a broader analysis pipeline (i.e. inputs/outputs)
1. demonstrate specific SQL and R code to achieve this</p>
<p>This first post will focus on the first two points.</p>
<p>The analysis pipeline:
punch raw data -&gt; clean data for db -&gt; insert data into db (via app) -&gt; receive informative error messages -&gt; repeat until successful -&gt; PostgreSQL functions tidy data -&gt; read tidied data into R for analysis</p>
<p>For a bit of context, I worked on a a number of multi-year acoustic telemetry studies for freshwater fish while working with <a href="https://poissonconsulting.ca">Poisson Consulting</a>. Our approach was very similar to the above. However, R came into the picture much sooner (i.e. around the clean stage) and remained there. We used R to check the data within the app (Shiny), R to tidy the data, etc. The approach I am proposing here removes R until the analysis stage and moves the preceding code into SQL functions within the database itself. Why?</p>
<ol style="list-style-type: decimal">
<li>Moves processing time (from tidying) into the data insert stage, thus reducing time needed to read tidied output at the other end of the pipeline (e.g. by app)</li>
<li>Removes the need for Shiny (although Shiny may still be a useful option for a number of reasons) by simply providing tidied output tables from the db itself.</li>
<li>Removes potential error casued by translating data checking from R to SQL (i.e. if the db rejects then that is that…whereas if checking r objects and hoping you have enough checks that then the SQL insert will work)<br />
</li>
<li>This bakes in the tidying code at the database design stage, thus removing the need to carry over (broken?) R code year to year.<br />
</li>
<li>take advantage of PostGIS (faster spatial operations on db itself).</li>
</ol>
<p>Correct management of datetime and spatial data</p>
